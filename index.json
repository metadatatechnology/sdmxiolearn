[{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/data-conversion-fundamentals/001-sdmx-data-transmission-formats/","title":"Unit 01 SDMX data transmission formats primer","tags":["SDMX"],"description":"Unit 01 SDMX data transmission formats primer","content":"SDMX data transmission formats The SDMX standard has 12 different formats for transmitting statistical data:\nType Version of the standard Format Currency EDI SDMX 1.0 GESMES/TS EDIFACT data message current XML SDMX 1.0 / 2.0 SDMX-ML Generic (time-series) data message obsolete XML SDMX 1.0 / 2.0 SDMX-ML Compact (time-series) data message obsolete XML SDMX 1.0 / 2.0 SDMX-ML Utility (time-series) data message obsolete XML SDMX 1.0 / 2.0 SDMX-ML Cross-Sectional data message obsolete XML SDMX 2.1 SDMX-ML Generic data messages for observations, time-series and cross-sectional data current XML SDMX 2.1 SDMX-ML Structure-Specific data messages for observations, time-series and cross-sectional data current XML SDMX 3.0 SDMX-ML Structure-Specific data message current JSON SDMX 2.1 SDMX-JSON version 1 data message current JSON SDMX 3.0 SDMX-JSON version 2 data message current CSV SDMX 2.1 SDMX-CSV version 1 data message current CSV SDMX 3.0 SDMX-CSV version 2 data message current Many dating from SDMX versions 1.0 and 2.0 are effectively obsolete, however EDI remains in use.\nFormat use cases The different formats suit some use cases better than others:\nEDI:\nterse allowing smaller file sizes but the GESMES/TS EDIFACT message does not support newer information model features introduced in SDMX 3.0 like multi-value attributes XML:\nhuman readable making it a good all purpose format but is relatively verbose resulting in large file sizes making compression needed for efficient transmission JSON:\neasily read and manipulated by JavaScript and similar languages making it a good format for driving data publication websites and software tools CSV:\nrelatively easy to create using standard software tools and programming techniques also easy to read using Excel, BI tools and similar software however the flattening of the data into a two-dimensional table makes datasets more verbose because component values are repeated for each observation In the next units In the following units we\u0026rsquo;ll take a closer look at each of the formats in turn starting with XML which is the most commonly used.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/getting-start-running-in-docker/","title":"SIO-2201 Running FMR in Docker","tags":[],"description":"Course Introduction","content":"Getting started with Fusion Metadata Registry - running FMR in Docker Module introduction Welcome to this module on getting started with Fusion Metadata Registry and specifically how to run the software in Docker.\nFusion Metadata Registry (FMR) is a free to use software tool for working with SDMX structures and data.\nYou\u0026rsquo;ll need two things to start working effectively with FMR:\na basic understanding of the SDMX information model; and a running installation of the FMR software. FMR is a Java web application so it will run on a range of computing platforms including Windows, Mac and Linux. However, it requires a number of other software components including a Java runtime environment, a Java web application server and a SQL database service such as MySQL or SQL Server.\nFortunately there is a simpler way to get working in less than 10 minutes - running FMR as a Docker container.\nThis module will help you learn about what FMR is, the use cases it serves, SDMX information model fundamentals and the how to run FMR in Docker.\nLearning objectives Understand what FMR is and its role as a structural metadata registry Learn the fundamentals of the SDMX 3.0 information model Understand the principles of software \u0026lsquo;containerisation\u0026rsquo; and how Docker can be used for that purpose Installation and basic operation of Docker Desktop How to create and run FMR in a container using Docker Desktop Prerequisites Prerequisites\nA basic understanding of the core SDMX concepts and the key metadata structures would be helpful including: Data Structure Definition, Concept, Codelist and Dataflow.\nUnits in this module Unit 01 About structural metadata and \u0026#39;metadata registries\u0026#39; Unit 02 What is FMR? Unit 03 SDMX 3.0 information model fundamentals Unit 04 What is Docker Unit 05 Install and operate Docker Desktop Unit 06 Create and run an FMR Docker container "},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/getting-start-running-in-docker/001-structural-metadata-and-metadata-registry/","title":"Unit 01 About structural metadata and &#39;metadata registries&#39;","tags":["Docker"],"description":"","content":"\nWhat is a \u0026lsquo;metadata registry\u0026rsquo;? Wikipedia tells us that a metadata registry is a central location in an organisation where metadata definitions are stored and maintained in a controlled method.\nA metadata registry can therefore be thought of as a database for metadata.\nAbout \u0026lsquo;structural metadata\u0026rsquo; Fusion Metadata Registry focuses principally on structural metadata.\nIn SDMX, structural metadata are the Concepts, Codelists, Data Structure Definitions (DSDs) and other artefacts that together can be used for modelling statistical data domains.\nStructural metadata is often referred to simply as \u0026lsquo;structures\u0026rsquo;, and we\u0026rsquo;ll use that terminology in this module.\nFrom FMR 11, reference metadata can also be stored because SDMX 3.0 treats reference metadata sets (also called reference metadata reports) as structural metadata objects.\nFMR implements the SDMX Registry specification Section 5 of the SDMX technical specifications sets out precisely what functions a metadata registry should perform and the interfaces it provides. Fusion Metadata Registry is designed to these specifications meaning that it should work with other SDMX software tools and systems.\nIn particular, the FMR enables:\nthe submission (storage); maintenance (update); retrieval of structures. It supports most of the SDMX standard structural metadata transmission formats including:\nSDMX-ML - XML SDMX-JSON - JSON EDI Structures can therefore be easily exchanged with other organisations and used with other SDMX software tools that also accept the standard transmission formats.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/data-conversion-fundamentals/","title":"SIO-2202 Data conversion fundamentals","tags":[],"description":"Course Introduction","content":"SDMX data conversion fundamentals using Fusion Metadata Registry Module introduction The SDMX standard provides 12 alternative formats for transmitting data including EDI, JSON, CSV and seven different variants of XML.\nIn this module we look at precisely what these formats are, which ones are most useful and how to use Fusion Metadata Registry to convert SDMX datasets between them.\nLearning objectives Gain a basic understanding of the common SDMX data transmission formats including the most-used XML formats, JSON, CSV and EDI, plus Fusion Metadata Registry\u0026rsquo;s own Excel format How to convert datasets to different transmission formats interactively using the FMR web user interface The SDMX-ML 2.1 structure specific \u0026lsquo;quick convert\u0026rsquo; function Principles of how to use FMR\u0026rsquo;s data transformation REST API for converting datasets programmatically Prerequisites Prerequisites\nA basic understanding of the core SDMX concepts and the key metadata structures would be helpful including: Data Structure Definition, Concept, Codelist and Dataflow.\nUnits in this module Unit 01 SDMX data transmission formats primer Unit 02 SDMX XML data transmission formats Unit 03 SDMX JSON data transmission formats Unit 04 SDMX CSV data transmission formats Unit 05 EDI data transmission formats "},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/data-conversion-fundamentals/002-xml-formats/","title":"Unit 02 SDMX XML data transmission formats","tags":["XML"],"description":"Unit 02 SDMX XML data transmission formats","content":"Introduction The XML data transmission format was introduced with SDMX 1.0 and is known as SDMX-ML data.\nIt provides a good balance between usability, human readability and transmission efficiency - particularly if compressed. These characteristics in addition to its early introduction have made XML the most widely used format.\nSince SDMX 1.0, the standard has accumulated seven different variants of the XML data format.\nIn this unit we\u0026rsquo;ll look at the three most relevant:\nSDMX-ML 2.1 Generic data message SDMX-ML 2.1 Structure-specific data message SDMX-ML 3.0 Structure-specific data message SDMX-ML 2.1 Generic data message The Generic message is characterised by having a fixed XML schema irrespective of the structure of the dataset.\nBy contrast, the structure-specific XML schema is variable and defined by the dataset\u0026rsquo;s DSD. While a little more verbose, the fixed schema can make it easier to create and process Generic messages because the XML structure is always the same.\nThe SDMX-ML 2.1 Generic data message aligns with the SDMX 2.1 information model.\nExample:\nThe example below is an excerpt from a Generic data message.\nA Generic Dataset consists of a sequence of Series elements.\nYou\u0026rsquo;ll note that a series starts by defining its SeriesKey which sets the dimension values followed by a sequence of obs observation elements containing the time period and its associated observation value.\n\u0026lt;message:DataSet structureRef=\u0026#34;WB_GCI_1_0\u0026#34;\u0026gt; \u0026lt;generic:Series\u0026gt; \u0026lt;generic:SeriesKey\u0026gt; \u0026lt;generic:Value id=\u0026#34;REF_AREA\u0026#34; value=\u0026#34;GHA\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;INDICATOR\u0026#34; value=\u0026#34;GCI\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;SUB_INDICATOR\u0026#34; value=\u0026#34;RANK\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;FREQ\u0026#34; value=\u0026#34;A\u0026#34;/\u0026gt; \u0026lt;/generic:SeriesKey\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2008\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;102\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2009\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2010\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; See the complete message... \u0026lt;message:GenericData xmlns:footer=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message/footer\u0026#34; xmlns:generic=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/data/generic\u0026#34; xmlns:common=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/common\u0026#34; xmlns:message=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message https://registry.sdmx.org/schemas/v2_1/SDMXMessage.xsd\u0026#34;\u0026gt; \u0026lt;message:Header\u0026gt; \u0026lt;message:ID\u0026gt;IREF353870\u0026lt;/message:ID\u0026gt; \u0026lt;message:Test\u0026gt;false\u0026lt;/message:Test\u0026gt; \u0026lt;message:Prepared\u0026gt;2022-08-17T11:23:05Z\u0026lt;/message:Prepared\u0026gt; \u0026lt;message:Sender id=\u0026#34;Unknown\u0026#34;/\u0026gt; \u0026lt;message:Receiver id=\u0026#34;guest\u0026#34;/\u0026gt; \u0026lt;message:Structure structureID=\u0026#34;WB_GCI_1_0\u0026#34; dimensionAtObservation=\u0026#34;TIME_PERIOD\u0026#34;\u0026gt; \u0026lt;common:StructureUsage\u0026gt; \u0026lt;Ref agencyID=\u0026#34;WB\u0026#34; id=\u0026#34;GCI\u0026#34; version=\u0026#34;1.0\u0026#34;/\u0026gt; \u0026lt;/common:StructureUsage\u0026gt; \u0026lt;/message:Structure\u0026gt; \u0026lt;message:DataSetAction\u0026gt;Information\u0026lt;/message:DataSetAction\u0026gt; \u0026lt;message:Extracted\u0026gt;2022-08-17T11:23:05\u0026lt;/message:Extracted\u0026gt; \u0026lt;message:ReportingBegin\u0026gt;2008-01-01T00:00:00\u0026lt;/message:ReportingBegin\u0026gt; \u0026lt;message:ReportingEnd\u0026gt;2017-01-01T23:59:59\u0026lt;/message:ReportingEnd\u0026gt; \u0026lt;/message:Header\u0026gt; \u0026lt;message:DataSet structureRef=\u0026#34;WB_GCI_1_0\u0026#34;\u0026gt; \u0026lt;generic:Series\u0026gt; \u0026lt;generic:SeriesKey\u0026gt; \u0026lt;generic:Value id=\u0026#34;REF_AREA\u0026#34; value=\u0026#34;GHA\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;INDICATOR\u0026#34; value=\u0026#34;GCI\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;SUB_INDICATOR\u0026#34; value=\u0026#34;RANK\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;FREQ\u0026#34; value=\u0026#34;A\u0026#34;/\u0026gt; \u0026lt;/generic:SeriesKey\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2008\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;102\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2009\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2010\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2011\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2012\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;103\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2013\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2014\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;111\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2015\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;119\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2016\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2017\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;111\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;/generic:Series\u0026gt; \u0026lt;generic:Series\u0026gt; \u0026lt;generic:SeriesKey\u0026gt; \u0026lt;generic:Value id=\u0026#34;REF_AREA\u0026#34; value=\u0026#34;GHA\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;INDICATOR\u0026#34; value=\u0026#34;GCI\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;SUB_INDICATOR\u0026#34; value=\u0026#34;VALUE\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;FREQ\u0026#34; value=\u0026#34;A\u0026#34;/\u0026gt; \u0026lt;/generic:SeriesKey\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2008\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.616139933\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2009\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.448062477\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2010\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.55568976\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2011\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.64915433\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2012\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.792629136\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2013\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.693773108\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2014\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.713529283\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2015\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.582722052\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2016\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.679439434\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;generic:Obs\u0026gt; \u0026lt;generic:ObsDimension value=\u0026#34;2017\u0026#34;/\u0026gt; \u0026lt;generic:ObsValue value=\u0026#34;3.72270246361418\u0026#34;/\u0026gt; \u0026lt;/generic:Obs\u0026gt; \u0026lt;/generic:Series\u0026gt; \u0026lt;/message:DataSet\u0026gt; \u0026lt;/message:GenericData\u0026gt; SDMX-ML 2.1 Structure-specific data message Unlike Generic, the Structure-specific messages\u0026rsquo;s XML elements and XML attributes are defined by the Data Structure Definitions of the datasets being transmitted. This approach provides two key benefits:\nThe datasets\u0026rsquo; validity can be checked by validating the XML message against its XML schema using standard XML processing tools The message is less verbose - for this reason Compact is used as another name for Structure-specific Note that \u0026lsquo;validity\u0026rsquo; in this case concerns the following:\nConformance of the dataset to the defined Data Structure Definition - does it have the right SDMX Dimensions and Attributes Mandatory attributes are reported The value of each Dimension, Attribute and Measure complies with the component\u0026rsquo;s defined representation - for coded components for example, the values must appear in the relevant Codelists Compliance with any defined Constraints The SDMX-ML 2.1 Structure-specific data message aligns with the SDMX 2.1 information model.\nExample:\nThe excerpt from a Structure-specific message below illustrates the principles.\nThe XML attributes of the Series element are specific to the DSD for this dataset so refer directly to the DSD\u0026rsquo;s Dimensions (REF_AREA, INDICATOR etc) rather than using key-value pairs. Any Series Attributes would also be included as explicit XML attributes of the Series element. Similarly, Observation Attributes would be included as XML attributes of the Obs elements.\n\u0026lt;Series REF_AREA=\u0026#34;GHA\u0026#34; INDICATOR=\u0026#34;GCI\u0026#34; SUB_INDICATOR=\u0026#34;RANK\u0026#34; FREQ=\u0026#34;A\u0026#34;\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2008\u0026#34; OBS_VALUE=\u0026#34;102\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2009\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2010\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2011\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2012\u0026#34; OBS_VALUE=\u0026#34;103\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2013\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2014\u0026#34; OBS_VALUE=\u0026#34;111\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2015\u0026#34; OBS_VALUE=\u0026#34;119\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2016\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2017\u0026#34; OBS_VALUE=\u0026#34;111\u0026#34;/\u0026gt; \u0026lt;/Series\u0026gt; \u0026lt;Series REF_AREA=\u0026#34;GHA\u0026#34; INDICATOR=\u0026#34;GCI\u0026#34; SUB_INDICATOR=\u0026#34;VALUE\u0026#34; FREQ=\u0026#34;A\u0026#34;\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2008\u0026#34; OBS_VALUE=\u0026#34;3.616139933\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2009\u0026#34; OBS_VALUE=\u0026#34;3.448062477\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2010\u0026#34; OBS_VALUE=\u0026#34;3.55568976\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2011\u0026#34; OBS_VALUE=\u0026#34;3.64915433\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2012\u0026#34; OBS_VALUE=\u0026#34;3.792629136\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2013\u0026#34; OBS_VALUE=\u0026#34;3.693773108\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2014\u0026#34; OBS_VALUE=\u0026#34;3.713529283\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2015\u0026#34; OBS_VALUE=\u0026#34;3.582722052\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2016\u0026#34; OBS_VALUE=\u0026#34;3.679439434\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2017\u0026#34; OBS_VALUE=\u0026#34;3.72270246361418\u0026#34;/\u0026gt; \u0026lt;/Series\u0026gt; See the complete message... \u0026lt;message:StructureSpecificData xmlns:ss=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/data/structurespecific\u0026#34; xmlns:footer=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message/footer\u0026#34; xmlns:ns1=\u0026#34;urn:sdmx:org.sdmx.infomodel.datastructure.Dataflow=WB:GCI(1.0):ObsLevelDim:TIME_PERIOD\u0026#34; xmlns:message=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message\u0026#34; xmlns:common=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/common\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message https://registry.sdmx.org/schemas/v2_1/SDMXMessage.xsd urn:sdmx:org.sdmx.infomodel.datastructure.Dataflow=WB:GCI(1.0):ObsLevelDim:TIME_PERIOD https://demo11.metadatatechnology.com/FusionRegistry/ws/public/sdmxapi/rest/schema/dataflow/WB/GCI/1.0?format=sdmx-2.1\u0026#34;\u0026gt; \u0026lt;message:Header\u0026gt; \u0026lt;message:ID\u0026gt;IREF378771\u0026lt;/message:ID\u0026gt; \u0026lt;message:Test\u0026gt;false\u0026lt;/message:Test\u0026gt; \u0026lt;message:Prepared\u0026gt;2022-08-17T12:04:37Z\u0026lt;/message:Prepared\u0026gt; \u0026lt;message:Sender id=\u0026#34;Unknown\u0026#34;/\u0026gt; \u0026lt;message:Receiver id=\u0026#34;guest\u0026#34;/\u0026gt; \u0026lt;message:Structure structureID=\u0026#34;WB_GCI_1_0\u0026#34; namespace=\u0026#34;urn:sdmx:org.sdmx.infomodel.datastructure.Dataflow=WB:GCI(1.0):ObsLevelDim:TIME_PERIOD\u0026#34; dimensionAtObservation=\u0026#34;TIME_PERIOD\u0026#34;\u0026gt; \u0026lt;common:StructureUsage\u0026gt; \u0026lt;Ref agencyID=\u0026#34;WB\u0026#34; id=\u0026#34;GCI\u0026#34; version=\u0026#34;1.0\u0026#34;/\u0026gt; \u0026lt;/common:StructureUsage\u0026gt; \u0026lt;/message:Structure\u0026gt; \u0026lt;message:DataSetAction\u0026gt;Information\u0026lt;/message:DataSetAction\u0026gt; \u0026lt;message:Extracted\u0026gt;2022-08-17T12:04:37\u0026lt;/message:Extracted\u0026gt; \u0026lt;message:ReportingBegin\u0026gt;2008-01-01T00:00:00\u0026lt;/message:ReportingBegin\u0026gt; \u0026lt;message:ReportingEnd\u0026gt;2017-01-01T23:59:59\u0026lt;/message:ReportingEnd\u0026gt; \u0026lt;/message:Header\u0026gt; \u0026lt;message:DataSet ss:dataScope=\u0026#34;DataStructure\u0026#34; xsi:type=\u0026#34;ns1:DataSetType\u0026#34; ss:structureRef=\u0026#34;WB_GCI_1_0\u0026#34;\u0026gt; \u0026lt;Series REF_AREA=\u0026#34;GHA\u0026#34; INDICATOR=\u0026#34;GCI\u0026#34; SUB_INDICATOR=\u0026#34;RANK\u0026#34; FREQ=\u0026#34;A\u0026#34;\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2008\u0026#34; OBS_VALUE=\u0026#34;102\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2009\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2010\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2011\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2012\u0026#34; OBS_VALUE=\u0026#34;103\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2013\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2014\u0026#34; OBS_VALUE=\u0026#34;111\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2015\u0026#34; OBS_VALUE=\u0026#34;119\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2016\u0026#34; OBS_VALUE=\u0026#34;114\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2017\u0026#34; OBS_VALUE=\u0026#34;111\u0026#34;/\u0026gt; \u0026lt;/Series\u0026gt; \u0026lt;Series REF_AREA=\u0026#34;GHA\u0026#34; INDICATOR=\u0026#34;GCI\u0026#34; SUB_INDICATOR=\u0026#34;VALUE\u0026#34; FREQ=\u0026#34;A\u0026#34;\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2008\u0026#34; OBS_VALUE=\u0026#34;3.616139933\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2009\u0026#34; OBS_VALUE=\u0026#34;3.448062477\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2010\u0026#34; OBS_VALUE=\u0026#34;3.55568976\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2011\u0026#34; OBS_VALUE=\u0026#34;3.64915433\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2012\u0026#34; OBS_VALUE=\u0026#34;3.792629136\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2013\u0026#34; OBS_VALUE=\u0026#34;3.693773108\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2014\u0026#34; OBS_VALUE=\u0026#34;3.713529283\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2015\u0026#34; OBS_VALUE=\u0026#34;3.582722052\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2016\u0026#34; OBS_VALUE=\u0026#34;3.679439434\u0026#34;/\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2017\u0026#34; OBS_VALUE=\u0026#34;3.72270246361418\u0026#34;/\u0026gt; \u0026lt;/Series\u0026gt; \u0026lt;/message:DataSet\u0026gt; \u0026lt;/message:StructureSpecificData\u0026gt; Changes to the data messages in SDMX 3.0 SDMX 3.0 rationalised the list of XML data transmission formats to just one: SDMX-ML 3.0 Structure-specific.\nNote that while the legacy SDMX 2.0 and 2.1 data formats including Generic were deprecated in SDMX 3.0 they remain valid for data transmission. However there are no equivalents in the latest version 3.0 of the SDMX standard.\nSDMX-ML 3.0 Structure-specific data message The SDMX-ML 3.0 Structure-specific data message follows the same principles and structure to the original SDMX 2.1 as set out above.\nThe key differences in the SDMX 3.0 variant are:\nsupport for multiple measures support for complex attributes and measures : multi-lingual values and arrays of values support for the transmission of reference metadata that is linked to data as part of the data message The excerpt below from an SDMX 3.0 Structure-specific message illustrates the \u0026lt;Comp\u0026gt; element which is used to structure complex objects within the message body:\n\u0026lt;message:DataSet xsi:type=\u0026#34;ns1:DataSetType\u0026#34; ss:structureRef=\u0026#34;ECB_EXR_COMPLEX_ATTRIBUTES_1_0\u0026#34;\u0026gt; \u0026lt;Series FREQ=\u0026#34;A\u0026#34; CURRENCY=\u0026#34;CAD\u0026#34; CURRENCY_DENOM=\u0026#34;EUR\u0026#34; EXR_TYPE=\u0026#34;SP00\u0026#34; EXR_SUFFIX=\u0026#34;A\u0026#34; TIME_FORMAT=\u0026#34;P1Y\u0026#34; COLLECTION=\u0026#34;A\u0026#34; DECIMALS=\u0026#34;4\u0026#34; TITLE_COMPL=\u0026#34;ECB reference exchange rate, Canadian dollar/Euro, 2:15 pm (C.E.T.)\u0026#34; UNIT=\u0026#34;CAD\u0026#34; UNIT_MULT=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;Comp id=\u0026#34;TITLE\u0026#34; xsi:type=\u0026#34;ns1:TITLE_ATTRIBUTE\u0026#34;\u0026gt; \u0026lt;Value\u0026gt; \u0026lt;common:Text xml:lang=\u0026#34;en\u0026#34;\u0026gt;Some English Text\u0026lt;/common:Text\u0026gt; \u0026lt;common:Text xml:lang=\u0026#34;fr\u0026#34;\u0026gt;Quelques textes en anglais\u0026lt;/common:Text\u0026gt; \u0026lt;/Value\u0026gt; \u0026lt;Value\u0026gt; \u0026lt;common:Text\u0026gt;Additional English Text where lang defaults to en\u0026lt;/common:Text\u0026gt; \u0026lt;common:Text xml:lang=\u0026#34;fr\u0026#34;\u0026gt;Texte anglais suppl√©mentaire\u0026lt;/common:Text\u0026gt; \u0026lt;/Value\u0026gt; \u0026lt;/Comp\u0026gt; \u0026lt;Comp id=\u0026#34;SOURCE_AGENCY\u0026#34; xsi:type=\u0026#34;ns1:SOURCE_AGENCY_ATTRIBUTE\u0026#34;\u0026gt; \u0026lt;Value\u0026gt;4F0\u0026lt;/Value\u0026gt; \u0026lt;Value\u0026gt;4D0\u0026lt;/Value\u0026gt; \u0026lt;Value\u0026gt;CZ2\u0026lt;/Value\u0026gt; \u0026lt;/Comp\u0026gt; \u0026lt;Comp id=\u0026#34;SOURCE_PUB\u0026#34; xsi:type=\u0026#34;ns1:SOURCE_PUB_ATTRIBUTE\u0026#34;\u0026gt; \u0026lt;Value\u0026gt;First publication source\u0026lt;/Value\u0026gt; \u0026lt;Value\u0026gt;Second publication source\u0026lt;/Value\u0026gt; \u0026lt;/Comp\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2017\u0026#34; OBS_VALUE=\u0026#34;1.46472274509804\u0026#34;\u0026gt; \u0026lt;Comp id=\u0026#34;OBS_STATUS\u0026#34; xsi:type=\u0026#34;ns1:OBS_STATUS_ATTRIBUTE\u0026#34;\u0026gt; \u0026lt;Value\u0026gt;A\u0026lt;/Value\u0026gt; \u0026lt;Value\u0026gt;F\u0026lt;/Value\u0026gt; \u0026lt;/Comp\u0026gt; \u0026lt;/Obs\u0026gt; \u0026lt;Obs TIME_PERIOD=\u0026#34;2018\u0026#34; OBS_VALUE=\u0026#34;1.529364705882353\u0026#34;\u0026gt; \u0026lt;Comp id=\u0026#34;OBS_STATUS\u0026#34; xsi:type=\u0026#34;ns1:OBS_STATUS_ATTRIBUTE\u0026#34;\u0026gt; \u0026lt;Value\u0026gt;J\u0026lt;/Value\u0026gt; \u0026lt;Value\u0026gt;U\u0026lt;/Value\u0026gt; \u0026lt;Value\u0026gt;N\u0026lt;/Value\u0026gt; \u0026lt;/Comp\u0026gt;\t\u0026lt;/Obs\u0026gt; Obsolete SDMX 1.0/2.0 XML data messages SDMX versions 1.0 and 2.0 specified four additional XML data messages all of which are effectively obsolete but may still be used by some systems and organisations:\nSDMX-ML 1.0/2.0 Generic (time-series) data message - general format for exchange of SDMX time-series datasets using a fixed XML schema SDMX-ML 1.0/2.0 Compact (time-series) data message - same principle as SDMX-ML 2.1 structure specific in that the message\u0026rsquo;s XML schema is defined by the dataset\u0026rsquo;s DSD making it more \u0026lsquo;compact\u0026rsquo; SDMX-ML 1.0/2.0 Utility (time data) data message - a little used alternative to Generic SDMX-ML 1.0/2.0 Cross-Sectional data message - a message format designed for exchange of cross-sectional data but little used in practice XML \u0026lsquo;series keys only\u0026rsquo; data messages A data message can optionally carry just the series keys without observation values as illustrated using the Generic message below.\n\u0026lt;generic:Series\u0026gt; \u0026lt;generic:SeriesKey\u0026gt; \u0026lt;generic:Value id=\u0026#34;REF_AREA\u0026#34; value=\u0026#34;GHA\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;INDICATOR\u0026#34; value=\u0026#34;GCI\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;SUB_INDICATOR\u0026#34; value=\u0026#34;RANK\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;FREQ\u0026#34; value=\u0026#34;A\u0026#34;/\u0026gt; \u0026lt;/generic:SeriesKey\u0026gt; \u0026lt;/generic:Series\u0026gt; \u0026lt;generic:Series\u0026gt; \u0026lt;generic:SeriesKey\u0026gt; \u0026lt;generic:Value id=\u0026#34;REF_AREA\u0026#34; value=\u0026#34;GHA\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;INDICATOR\u0026#34; value=\u0026#34;GCI\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;SUB_INDICATOR\u0026#34; value=\u0026#34;VALUE\u0026#34;/\u0026gt; \u0026lt;generic:Value id=\u0026#34;FREQ\u0026#34; value=\u0026#34;A\u0026#34;/\u0026gt; \u0026lt;/generic:SeriesKey\u0026gt; \u0026lt;/generic:Series\u0026gt; \u0026lsquo;Series keys only\u0026rsquo; messages find application in use cases where knowledge of the data available is required but the precise observations are not, for instance in interactive \u0026lsquo;data discovery\u0026rsquo; software tools for data consumers.\nTips and points to note The Generic and Structure-specific XML formats are the most useful and those most likely to be encountered in practice.\nThe SDMX-ML 3.0 Structure-specific data message is the only option for datasets that use information model features introduced in version 3.0 including multi-value and multi-lingual attributes and measures.\nSimlarly the SDMX 3.0 Structure-specific data message must be used for transmission of Reference Metadata with the data when following the SDMX 3.0 model for reference metadata.\nRecap The SDMX standard has seven alternative formats for data transmission using XML The SDMX 2.1 Generic message is commonly used and benefits from a fixed schema that is often simpler to create and interpret The SDMX 2.1 Structure specific message is similarly in common usage, it\u0026rsquo;s less verbose and allows validation of the dataset by validating the XML message against its DSD-specific XML schema SDMX 3.0 Structure-specific is the only XML data message for SDMX 3.0 use cases - it follows the same principles as the earlier SDMX 2.1 message with additional support for information model features introduced in SDMX 3.0 including multiple measures and multi-value attributes \u0026lsquo;Series keys only\u0026rsquo; data messages carry just the series keys and omit the observation values In the next unit In the next unit we\u0026rsquo;ll look at the SDMX-JSON data transmission messages.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/getting-start-running-in-docker/002-what-is-fmr/","title":"Unit 02 What is FMR?","tags":["Docker"],"description":"","content":"FMR uses the SDMX 3.0 information model FMR 11 uses the SDMX 3.0 information model internally for storing and organising the structural metadata it holds.\nWe\u0026rsquo;ll look at the SDMX 3.0 information model in more detail in the next module, but for now the key point is that FMR 11 is able to natively work with the structures as defined in SDMX 3.0.\nSDMX 2.1 structures are supported for backward compatibility where possible. Fortunately most are fully compatible with SDMX 3.0 meaning that they can be stored in and retrieved from FMR 11.\nHowever, there are two SDMX 2.1 structures that are not directly supported by SDMX 3.0:\nStructure Set - this has been replaced by Structure Maps Hierarchical Codelist - replaced by Hierarchy In these two cases, SDMX 2.1 structures will be converted to their SDMX 3.0 equivalent on load into the Registry. The transformation is one-way meaning that, once loaded, the original SDMX 2.1 structures cannot be recreated.\nFMR will also validate, transform (map) and convert SDMX datasets In addition to its core role storing structural metadata, FMR also provides three data processing services:\nData validation FMR will validate loaded datasets by applying nine quality rules which include:\nchecking that the data matches the Data Structure Definition the \u0026lsquo;representation\u0026rsquo; is correct - generally that the codes in the data are in the relevant Codelists the data complies with any defined \u0026lsquo;constraints\u0026rsquo; - a constraint for instance may be defined to limit the regions a specific data provider can report data for all mandatory attributes are included in the data \u0026lsquo;balance equalities\u0026rsquo; - any observations between series that should be consistent with one another as is often the case with financial data\nData transformation / mapping In the SDMX 3.0 information model, Structure Maps can be used to define the transformation of data from one Data Structure Definition to another. Typical use cases include transforming data received to the structure needed for internal processing, and transforming internal datasets to a simpler structure better suited to public publication.\nUsing FMR, a Structure Map can be created and tested and used to actually transform datasets to the new structure.\nData conversion FMR will convert datasets between the SDMX data transmission formats. For instance, data loaded in SDMX-CSV can be converted to SDMX-ML (XML), SDMX-JSON or EDI.\nIt\u0026rsquo;s also possible to load data from Excel workbooks - but the worksheet containing the data must use a layout that is specific to FMR.\nSDMX REST Application Programming Interface (API) in FMR FMR implements the SDMX standard REST application programming interface (API) for:\nStructure queries Structure specific schemas SDMX has two versions of the REST API:\nVersion 1 of the REST API accompanied SDMX 2.1\nVersion 2 of the REST API accompanies SDMX 3.0\nFMR 11 supports support version 2, and also version 1 for backward compatibility.\nDetails of the SDMX REST APIs are out of scope for this course, but it may be helpful to read the documentation on GitHub:\nVersion 2 structure query API documentation\nVersion 1 structure query API documentation\nThe schema API generates XML schemas for validating SDMX XML structure specific datasets using generic XML software tools like XML Spy. Again, the detail of this is outside the scope of this course but the documentation provides further reading.\nFMR provides a web user interface In addition to the REST API, FMR also provides a web user interface.\nA standard web browser (e.g. Chrome, Microsoft Edge, Safari) is all that is needed.\nThe web user interface provides the following main functions:\nBrowse, view and download any of the structures stored in the Registry Author new structures Maintain and modify existing structures Import structures from file or from another SDMX REST API service such as that provided by the SDMX Global Registry Process data using the validation, transformation (mapping) and conversion services Configure and administer the software Recap FMR is primarily a structural metadata registry whose main purpose is storage of SDMX structural metadata FMR 11 supports the SDMX 3.0 information model but will also work transparently with SDMX 2.1 structures except in the case of Structure Sets and Hierarchical Codelists FMR also provides three data processing services: validation, transformation (mapping) and data transmission format conversion There are two interfaces: SDMX-compliant REST API for automation Web user interface for interactively working with the Registry\u0026rsquo;s structural metadata content and processing data using its validation, transformation (mapping) and conversion services In the next unit In the next unit we\u0026rsquo;ll look in more detail at the SDMX 3.0 information model, the key structural metadata artefacts and how they relate to one another.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/data-conversion-fundamentals/003-json-formats/","title":"Unit 03 SDMX JSON data transmission formats","tags":["JSON"],"description":"Unit 03 SDMX JSON data transmission formats","content":"Introduction JSON was introduced as a transmission format for both structures and data as an addition to SDMX 2.1. Unlike XML there are only two versions of the data message.\nIn this unit we\u0026rsquo;ll look at the general principles of the JSON data message and note the differences between the two versions.\nSDMX-JSON v1 data transmission message The SDMX-JSON v1 data message specification was added to SDMX 2.1 principally to satisfy the use case for data dissemination on the Internet where JSON is easier to use for websites and web data publication applications.\nSDMX-JSON differs from its XML counterparts in that it transmits both the classification identifiers and their labels. This has the advantage of packaging all the information required to display a dataset in a single message. The XML messages by contrast require applications also have access to the dataset\u0026rsquo;s structural metadata in order to decode enumerated values in particular.\nThe basic structure of a message is as follows:\n{ \u0026#34;meta\u0026#34; : { header information }, \u0026#34;data\u0026#34; : { \u0026#34;datasets\u0026#34; : [ {array of one or more datasets} ], \u0026#34;structures\u0026#34; : { the structural metadata for the datasets} } } The datasets element carries an array of one or more datasets with their accompanying series and observation values. However, the metadata in terms of the component Ids, Names, Descriptions, and the observation time period values are under the structures element and referenced using a zero-based index string of the form 0:0:1:0.\nThe exerpt of a single series below shows this in context. The 0:0:1:0 indicates there are four dimensions respectively referencing the first, first, second and first codes in their codelists defined in the structures section.\n\u0026#34;series\u0026#34;: { \u0026#34;0:0:1:0\u0026#34;: { \u0026#34;attributes\u0026#34;: [], \u0026#34;observations\u0026#34;: { \u0026#34;0\u0026#34;: [\u0026#34;102\u0026#34;], \u0026#34;1\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;2\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;3\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;4\u0026#34;: [\u0026#34;103\u0026#34;], \u0026#34;5\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;6\u0026#34;: [\u0026#34;111\u0026#34;], \u0026#34;7\u0026#34;: [\u0026#34;119\u0026#34;], \u0026#34;8\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;9\u0026#34;: [\u0026#34;111\u0026#34;] } }, This approach of decoupling the metadata from the data is designed to minimise the size of the message by avoiding duplication.\nSee the complete message... { \u0026#34;meta\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;IREF519002\u0026#34;, \u0026#34;prepared\u0026#34;: \u0026#34;2022-08-17T15:58:26\u0026#34;, \u0026#34;test\u0026#34;: false, \u0026#34;datasetId\u0026#34;: \u0026#34;5116be7f-5f35-49f1-9379-54449224bc57\u0026#34;, \u0026#34;sender\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;Unknown\u0026#34; }, \u0026#34;receiver\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;guest\u0026#34; }, \u0026#34;links\u0026#34;: [{ \u0026#34;rel\u0026#34;: \u0026#34;self\u0026#34;, \u0026#34;href\u0026#34;: \u0026#34;/data/WB,GCI,1.0/GHA.GCI..?format=sdmx-json\u0026#34;, \u0026#34;uri\u0026#34;: \u0026#34;https://raw.githubusercontent.com/sdmx-twg/sdmx-json/develop/structure-message/tools/schemas/1.0/sdmx-json-structure-schema.json\u0026#34; }] }, \u0026#34;data\u0026#34;: { \u0026#34;dataSets\u0026#34;: [{ \u0026#34;links\u0026#34;: [{ \u0026#34;rel\u0026#34;: \u0026#34;dataflow\u0026#34;, \u0026#34;urn\u0026#34;: \u0026#34;urn:sdmx:org.sdmx.infomodel.datastructure.Dataflow=WB:GCI(1.0)\u0026#34; }], \u0026#34;action\u0026#34;: \u0026#34;Information\u0026#34;, \u0026#34;series\u0026#34;: { \u0026#34;0:0:0:0\u0026#34;: { \u0026#34;attributes\u0026#34;: [], \u0026#34;observations\u0026#34;: { \u0026#34;0\u0026#34;: [\u0026#34;102\u0026#34;], \u0026#34;1\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;2\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;3\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;4\u0026#34;: [\u0026#34;103\u0026#34;], \u0026#34;5\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;6\u0026#34;: [\u0026#34;111\u0026#34;], \u0026#34;7\u0026#34;: [\u0026#34;119\u0026#34;], \u0026#34;8\u0026#34;: [\u0026#34;114\u0026#34;], \u0026#34;9\u0026#34;: [\u0026#34;111\u0026#34;] } }, \u0026#34;0:0:1:0\u0026#34;: { \u0026#34;attributes\u0026#34;: [], \u0026#34;observations\u0026#34;: { \u0026#34;0\u0026#34;: [\u0026#34;3.616139933\u0026#34;], \u0026#34;1\u0026#34;: [\u0026#34;3.448062477\u0026#34;], \u0026#34;2\u0026#34;: [\u0026#34;3.55568976\u0026#34;], \u0026#34;3\u0026#34;: [\u0026#34;3.64915433\u0026#34;], \u0026#34;4\u0026#34;: [\u0026#34;3.792629136\u0026#34;], \u0026#34;5\u0026#34;: [\u0026#34;3.693773108\u0026#34;], \u0026#34;6\u0026#34;: [\u0026#34;3.713529283\u0026#34;], \u0026#34;7\u0026#34;: [\u0026#34;3.582722052\u0026#34;], \u0026#34;8\u0026#34;: [\u0026#34;3.679439434\u0026#34;], \u0026#34;9\u0026#34;: [\u0026#34;3.72270246361418\u0026#34;] } } } }], \u0026#34;structure\u0026#34;: { \u0026#34;links\u0026#34;: [{ \u0026#34;rel\u0026#34;: \u0026#34;dataflow\u0026#34;, \u0026#34;urn\u0026#34;: \u0026#34;urn:sdmx:org.sdmx.infomodel.datastructure.Dataflow=WB:GCI(1.0)\u0026#34; }, { \u0026#34;rel\u0026#34;: \u0026#34;datastructure\u0026#34;, \u0026#34;urn\u0026#34;: \u0026#34;urn:sdmx:org.sdmx.infomodel.datastructure.DataStructure=WB:GCI(1.0)\u0026#34; }], \u0026#34;name\u0026#34;: \u0026#34;Global Competitiveness Index\u0026#34;, \u0026#34;names\u0026#34;: { \u0026#34;en\u0026#34;: \u0026#34;Global Competitiveness Index\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;Global Competitiveness Index\u0026#34;, \u0026#34;descriptions\u0026#34;: { \u0026#34;en\u0026#34;: \u0026#34;Global Competitiveness Index\u0026#34; }, \u0026#34;dimensions\u0026#34;: { \u0026#34;dataset\u0026#34;: [], \u0026#34;series\u0026#34;: [{ \u0026#34;id\u0026#34;: \u0026#34;REF_AREA\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Reference Area\u0026#34;, \u0026#34;keyPosition\u0026#34;: 0, \u0026#34;role\u0026#34;: null, \u0026#34;values\u0026#34;: [{ \u0026#34;id\u0026#34;: \u0026#34;GHA\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Ghana\u0026#34; }] }, { \u0026#34;id\u0026#34;: \u0026#34;INDICATOR\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Indicator\u0026#34;, \u0026#34;keyPosition\u0026#34;: 1, \u0026#34;role\u0026#34;: null, \u0026#34;values\u0026#34;: [{ \u0026#34;id\u0026#34;: \u0026#34;GCI\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Global Competitiveness Index\u0026#34; }] }, { \u0026#34;id\u0026#34;: \u0026#34;SUB_INDICATOR\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Sub Indicator\u0026#34;, \u0026#34;keyPosition\u0026#34;: 2, \u0026#34;role\u0026#34;: null, \u0026#34;values\u0026#34;: [{ \u0026#34;id\u0026#34;: \u0026#34;RANK\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Rank\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;VALUE\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Value\u0026#34; }] }, { \u0026#34;id\u0026#34;: \u0026#34;FREQ\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Frequency\u0026#34;, \u0026#34;keyPosition\u0026#34;: 3, \u0026#34;role\u0026#34;: null, \u0026#34;values\u0026#34;: [{ \u0026#34;id\u0026#34;: \u0026#34;A\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Annual\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;To be used for data collected or disseminated every year.\u0026#34; }] }], \u0026#34;observation\u0026#34;: [{ \u0026#34;id\u0026#34;: \u0026#34;TIME_PERIOD\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Time period\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The period of time or point in time to which the measured observation refers.\u0026#34;, \u0026#34;keyPosition\u0026#34;: 4, \u0026#34;role\u0026#34;: \u0026#34;time\u0026#34;, \u0026#34;values\u0026#34;: [{ \u0026#34;start\u0026#34;: \u0026#34;2008-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2008-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2008\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2008\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2009-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2009-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2009\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2009\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2010-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2010-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2010\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2010\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2011-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2011-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2011\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2011\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2012-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2012-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2012\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2012\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2013-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2013-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2013\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2013\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2014-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2014-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2014\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2014\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2015-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2015-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2015\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2015\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2016-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2016-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2016\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2016\u0026#34; }, { \u0026#34;start\u0026#34;: \u0026#34;2017-01-01T00:00:00\u0026#34;, \u0026#34;end\u0026#34;: \u0026#34;2017-12-31T23:59:59\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;2017\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;2017\u0026#34; }] }] }, \u0026#34;attributes\u0026#34;: { \u0026#34;dataset\u0026#34;: [], \u0026#34;series\u0026#34;: [], \u0026#34;observation\u0026#34;: [] } } } } SDMX-JSON v2 data transmission message The SDMX-JSON v2 data message was introduced with SDMX 3.0 and follows the same principles and structure but with additions to support the new information model features, principally:\nsupport for multiple measures support for complex attributes and measures : multi-lingual values and arrays of values support for the transmission of reference metadata that is linked to data as part of the data message Tips and points to note SDMX-JSON can be used for any data transmission use case, but is best suited for web data discovery and retrieval applications because it carries all of the data and metadata needed to build an effective user interface.\nThe SDMX-JSON message is equivalent to SDMX-ML Generic in that its JSON schema is fixed and not dependent on the datasets\u0026rsquo; DSDs.\nLike SDMX-ML, the \u0026lsquo;series keys only\u0026rsquo; messages carry just the series keys and omit the observation values.\nRecap The SDMX standard has two versions of the JSON data transmission message, both of which are in use v1 was introduced as an addition to SDMX 2.1 v2 was introduced with SDMX 3.0, follows the same principles and structure as the v1 message but with extensions to support the additional SDMX 3.0 information model features including multiple measures, complex attributes and reference metadata in transit with the data In the next unit In the next unit we\u0026rsquo;ll look at the options for using CSV for SDMX data transmission.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/getting-start-running-in-docker/003-sdmx30-information-model-fundamentals/","title":"Unit 03 SDMX 3.0 information model fundamentals","tags":["Docker"],"description":"","content":"In this unit In this unit we\u0026rsquo;ll take a high level look at the SDMX 3.0 information model that underpins Fusion Metadata Registry 11, why it\u0026rsquo;s important and which bits it\u0026rsquo;s worth knowing to help get started with FMR.\nThe SDMX 3.0 model overview The SDMX 3.0 information model has around 34 separate structures which can be used for modelling data domains, modelling data collection, data discovery and other purposes.\nContrast this to typical SQL relational database models that maybe have four or five structures: table, index, view, key constraint for instance.\nThe UML schematic below shows a reasonably complete overview of the SDMX 3.0 information model, missing out only Agency Scheme, Process and Reporting Taxonomy to help improve clarity.\nYou can download a PDF version of the information model schematic for reference.\nWhy is the information model important to FMR? The SDMX 3.0 information model is how FMR structures its metadata internally. A basic knowledge of the key SDMX structures is therefore needed to use the tool effectively.\nIt\u0026rsquo;s also useful to understand the interdependencies between structures which are illustrated by the arrows and lines in the UML schematics.\nThe excerpt above from the SDMX information model shows the Dataflow\u0026rsquo;s immediate dependencies.\nImportantly, it tells us that to create a Dataflow, the information model requires we also need: a Data Structure Definition (DSD) and at least one Concept.\nIn practice, DSDs and therefore Dataflows generally need Codelists as well to define the enumeration of their dimensions, attributes and measures. So creation of a Dataflow generally requires the following sequence:\nCreate Codelists for any enumerated Data Structure components. Create all of the required Concepts, referencing the relevant Codelist if enumerated Create the Data Structure Definition referencing the Concepts Create the Dataflow referencing the Data Structure Definition FMR enforces the referential integrity of its metadata FMR records, tracks and rigorously enforces these interdependencies between structures in order to maintain the referential integrity of its internal information model.\nThe model is said to be referentially correct if the graph of structures is complete such that no structure referenced by another is missing.\nIn practice this means two things:\nAs observed in the case of the Dataflow, structures cannot be created unless every structure they depend upon already exists. Deleting a structure requires that all other structures that depend on it must also be deleted. Attempting to delete a codelist in FMR will often require the deletion of DSDs and Dataflows that depend on it.\nSimilarly, attempting to load structural metadata from a file will result in rejection if not all references are satisfied.\nItems and item schemes The structures highlighted in blue in the information model schematics are items schemes.\nThese are containers for items including Codes, Concepts, Categories and Data Providers. Items can be individually identified because each has a unique SDMX Id. However they cannot be maintained separately and can only exist within their item scheme.\nKey artefacts for data domain modelling While there are over 30 structures in the complete information model, relatively few need to be used in order to get started with FMR.\nThe following structures are required for basic data domain modelling:\nConcepts for your data domain (plus a Concept Scheme to hold and organise them) Codelist and Codes Data Structure Definition Concept Schemes and their Concepts describe the data domain\u0026rsquo;s core concepts or represented variables.\nCodelists and Codes are closely related, precisely defining the enumerations for any concepts with enumerated representation.\nData Structure Definitions (DSDs) bring it all together describing the structure of the domain\u0026rsquo;s datasets in terms of their Dimensions, Attributes, and Measures, each of which is defined by a Concept.\nKey artefacts for modelling data collection The following structures are typically used for modelling data collections:\nData Structure Definition and dependencies Dataflow Data Constraint Provision Agreement Data Provider Scheme and Data Providers While Data Structure Definitions describe a class of datasets all with the same basic structure, Dataflows can be thought of as describing a specific dataset. In the Eurosystem, a range of separate Dataflows for National Accounts all use the same ESTAT:NA_MAIN Data Structure Definition.\nProvision Agreements define which Data Providers provide data for a specific Dataflow. For international organisations and others concerned with collecting data from multiple providers, the arrangement if typically modelled using a single Dataflow and multiple Provision Agreements, one for each data provider. A single provision agreement is sufficient for most other use cases where the owner of the Dataflow provides the data.\nData Constraints allow the Valid Universe of Data to be more closely defined and can be attached at four different levels:\nData Structure Definition Dataflow Data Provider Provision Agreement A typical Data Constraint may constrain a dataset\u0026rsquo;s valid geographical regions. The standard SDMX:CL_AREA codelist for instance lists many regions, but only a few may be relevant. Creating a constraint that limits values to: DE, ES and IT ensures that only observations for those regions are valid and helps improve data quality by preventing data beng reported for other regions in error. Attaching that constraint to the Data Structure Definition applies the restricton to all Dataflows that use it. Conversly, attaching it to a specific Provision Agreement enforces the rule only for that particular Data Provider and Dataflow.\nKey artefacts for data discovery Data discovery concerns the ability of consumers of published statistical data to find the datasets, series and data points they need. The following structures can be used for that purpose:\nCategory Scheme and Categories Hierarchy Hierarchy Association For data discovery, Categories are typically used to organise Dataflows into an arbitrary tree of topics helping users to find the datasets they need by navigating down from general themes to more specific topics.\nThe European Central Bank\u0026rsquo;s public Statistical Data Warehouse uses this approach:\nThe SDMX 3.0 Hierarchy structure replaces Hierarchical Codelists from SDMX 2.1 and serve much the same purpose allowing the definition of arbitrary hierarchy trees of codes, possibly from multiple Codelists. In principle, a software tool for searching an SDMX statistical data warehouse could present these trees as a way for users to search for specific codes.\nAs an example, consider a flat codelist of indicators. Creating a Hierarchy could allow the indicators to be organised into a subject-based tree that is more easily searched than a simple flat list.\nFinally to Hierarchy Association, this structure was added in SDMX 3.0 to allow Hierarchies to be directly associated with any other \u0026lsquo;identifiable\u0026rsquo; artefact in the information model (an identifiable is anything with an Id which includes Codes and Concepts). A common use case is defining the Hierarchy\u0026rsquo;s context, for example to assign a Hierarchy to a DSD Dimension but only in the context of a specific Dataflow.\nOther artefacts in the SDMX information model In concluding this lesson it\u0026rsquo;s worth mentioning the remaining structural metadata artefacts not already covered. Broadly these fit into four categories:\nReference Metadata In SDMX 3.0, modelling of Reference Metadata and its collection follows the same approach to that of data with structures for Metadata Structure Definition (MSD), Metadataflow, Metadata Constraint, Metadata Provision Agreement and Metadata Provider which are the direct analogues for the data counterparts.\nStructure Mapping We learnt in lesson 2 of FMR\u0026rsquo;s data processing services and its function for transforming (or mapping) datasets to a different structure. Those mapping rules are primarily defined by two structures: Structure Map and Representation Map. The information model also provides two other specialist maps in the form of the Concept Scheme Map and Category Scheme Map structures for mapping Concept Schemes and Category Schemes respectively. These are lesser used in practice.\nVTL (Validation and Transformation Language) A set of six structures make up the \u0026rsquo;transformation and expression\u0026rsquo; part of the information model and are used for structuring VTL programs as SDMX metadata objects such that they can be centralised, controlled and exchanged in the same way as DSDs and Codelists.\nSpecial-purpose Structures Two structures fall into this final category: Process and Reporting Taxonomy. These are typically only used by organisations with specific use cases. For the purposes of this course, it\u0026rsquo;s simply worth noting that they exist.\nRecap An understanding of the SDMX 3.0 information model is important to using FMR effectively because it describes how the metadata organised While the complete model has around 34 structures, around 10 are needed to cover the majority of common data-related use cases: Concept Codelist Data Structure Dataflow Provision Agreement Data Provider Data Constraint Hierarchy Hierarchy Association Category Scheme In the next unit In the next unit we\u0026rsquo;ll look at how to get a running FMR installation using the self-contained Docker image.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/mapping-microdata-to-timeseries/","title":"SIO-2203 Transform multi-measure non-time series data to time series","tags":[],"description":"Course Introduction","content":"Getting started with Fusion Metadata Registry - running FMR in Docker Module introduction Learning objectives Attain a basic understanding of the SDMX data transmission formats including EDI, 2.0, 2.1, 3.0 and Excel Converting datasets to different transmission formats interactively using the FMR web user interfaces The SDMX-ML 2.1 structure specific quick convert function Introduction to the FMR Data Transformation Web Service Prerequisites Prerequisites\nA basic understanding of the core SDMX concepts and the key metadata structures would be helpful including: Data Structure Definition, Concept, Codelist and Dataflow.\nUnits in this module "},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/data-conversion-fundamentals/004-csv-formats/","title":"Unit 04 SDMX CSV data transmission formats","tags":["CSV"],"description":"Unit 04 SDMX CSV data transmission formats","content":"Introduction CSV was introduced as a transmission format for data only as an addition to SDMX 2.1 and was subsequently updated with the release of SDMX 3.0.\nLike JSON, there are two distinct versions of the data message:\nversion 1 supports the SDMX 2.1 information model version 2 supports the SDMX 3.0 information model In this unit we\u0026rsquo;ll look at the general principles of the SDMX CSV data messages and note the differences between the two versions.\nSDMX-CSV v1 data transmission message The SDMX-CSV v1 data message specification was added to SDMX 2.1 to provide a more convenient way to work with SDMX datasets using standard software tools like Excel, \u0026lsquo;R\u0026rsquo;, Tableau, Power BI and other business intelligence and statistics packages.\nThe CSV follows a standard 2-dimensional table layout with fixed columns and one row per observation.\nThere must be one column for the dataflow, one column per dimension, one column for the primary measure and one column per attribute. All dimensions defined in the Dataflow\u0026rsquo;s Data Structure Definition (DSD) must be included.\nA header row defines the meaning of each column.\nIn the simple case the value of each component is just the Id:\nDATAFLOW, REF_AREA, INDICATOR, SUB_INDICATOR, FREQ, TIME_PERIOD, OBS_VALUE\rWB:GCI(1.0), GHA, GCI, RANK, A, 2008, 102\rWB:GCI(1.0), GHA, GCI, RANK, A, 2009, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2010, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2011, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2012, 103\rWB:GCI(1.0), GHA, GCI, RANK, A, 2013, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2014, 111 Component Names (sometimes called Labels) can also be included by encoding each value as Id : Name as follows:\nDATAFLOW, REF_AREA:Reference Area, INDICATOR:Indicator, SUB_INDICATOR:Sub Indicator, FREQ:Frequency, TIME_PERIOD:Time period, OBS_VALUE:Observation\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2008, 102\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2009, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2010, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2011, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2012, 103\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2013, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2014, 111 SDMX-CSV v2 data transmission message The SDMX-CSV v2 data message follows the same general principle of one observation per row.\nV2 was introduced with SDMX 3.0 and includes support for the additional features added to that version of the standard, in particular:\nmultiple measures complex attributes and measures : multi-lingual values and arrays of values transmission of reference metadata linked to the data as part of the data message Datasets are also no longer restricted to just Dataflows and can instead reference a Dataflow, Data Structure Definition or a Provision Agreement. SDMX-CSV v2 supports this by changing the first two columns to describe the structure type (STRUCTURE : dataflow, datastructure or dataprovision) and its Id (STRUCTURE_ID)\nIn addition, the third column now specifies the action type (ACTION) bringing CSV into line with the XML and JSON formats that already provide for this, and better supporting the data exchange use case. The SDMX technical specifications define four action types which are encoded in a v2 CSV message using single characters:\nI - Information - the data is intended for informational purposes only, but treated as Append by the receiver A - Append - instructs incremental update of existing observations by the received R - Replace - instructs the receiver that existing observations should be replaced or appended if they don\u0026rsquo;t already exist D - Delete - instructs the receiver to delete the referenced data There can be a mix of action types within a single data message.\nThe following simple example message has three observations for the dataflow ESTAT:CENS_91SMSTA(1.0) with an action type of I indicating that the data is for information purposes only. Note that OBS_STATUS is an optional observation level attribute.\nSTRUCTURE,STRUCTURE_ID,ACTION,FREQ,MARSTA,AGE,SEX,UNIT,GEO,TIME_PERIOD,OBS_VALUE,TIME_FORMAT,OBS_STATUS dataflow,ESTAT:CENS_91SMSTA(1.0),I,A,TOTAL,Y25-29,F,PER,FR,1991,2162398,P1Y, dataflow,ESTAT:CENS_91SMSTA(1.0),I,A,TOTAL,Y25-29,M,PER,FR,1991,2147582,P1Y, dataflow,ESTAT:CENS_91SMSTA(1.0),I,A,TOTAL,Y25-29,T,PER,FR,1991,4309980,P1Y, Tips and points to note Values that contain commas must be enclosed in double-quotes\nSome implementations support delimiters other than comma, semi-colon (;) for instance.\nRecap The SDMX standard has two versions of the CSV data transmission message, both of which are in use All SDMX-CSV messages have one observation per row v1 was introduced as an addition to SDMX 2.1 v2 was introduced with SDMX 3.0, follows the same principles and structure as the v1 message but with extensions to support the additional SDMX 3.0 information model features including multiple measures, complex attributes and reference metadata in transit with the data The v2 message also adds support for action type providing better support for the data exchange use case - v1 by contrast was best suited to data query response Replication of component Ids and possibly names (labels) for each observation make CSV inefficient for large datasets In the next unit In the next unit we\u0026rsquo;ll look at the legacy GESMES / EDIFACT EDI data message which remains in use\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/getting-start-running-in-docker/004-what-is-docker/","title":"Unit 04 What is Docker","tags":["Docker"],"description":"","content":" Skip this unit if you already understand the principles of Docker and containerisation.\nIn this unit In this lesson we\u0026rsquo;ll introduce just enough about Docker and the principles of \u0026lsquo;containerisation\u0026rsquo; in order to use it for running Fusion Metadata Registry.\nWhat is Docker? Docker is a software platform for building and running applications in containers.\nContainers are executable collections of software in which application code is packaged, along with its libraries and dependencies so that it can be run anywhere, whether it be on desktop, traditional IT, or the cloud.\nDocker describes a container as:\n\u0026ldquo;A container packages up code and its dependencies so the application runs quickly and reliably from one computing environment to another.\u0026rdquo;\nContainers offer two key advantages for running FMR:\nAll of the software components needed to run FMR are assembled, configured and pre-packaged meaning that the user simply needs to start the container to get a fully functioning installation. Containers can be run on any operating system that supports Docker - Windows, Linux, Apple Mac. There are also cloud services such as Google Cloud Run and Microsoft Azure. For this module, we\u0026rsquo;ll focus on running FMR on a desktop PC or laptop using Docker Desktop.\nContainers and images An image is template from which containers can be created.\nStarting from the FMR image, multiple separate containers can be created if needed each with their own isolated FMR installation complete with its own configuration and metadata content.\nThe Docker Hub image repository Docker Images are stored and can be retrieved from an image repository.\nDocker Hub is the main image repository and is where the FMR images are stored.\nAs we\u0026rsquo;ll see later, Docker provides commands to \u0026lsquo;pull\u0026rsquo; images from Docker Hub\nRunning Docker using Docker Desktop For personal and light production use, Docker Desktop provides a simple way to run containers on desktop PCs and laptops. It is free to use for small businesses and non-commercial applications.\nDocker Desktop has both a command line interface:\nand a graphical user interface:\nRecap Docker is a way to run applications like FMR in containers The FMR image is pre-configured with everything needed for a complete running installation The FMR image is a template from which multiple containers can be created if needed Docker Desktop is the simplest way to run FMR containers on desktop PCs and laptops In the next lesson In the next lesson we\u0026rsquo;ll look at how to install and operate Docker Desktop.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/mapping-split-or-combine-dimensions/","title":"SIO-2204 Split out or collapse dimensions for time series data","tags":[],"description":"Course Introduction","content":"Split out or collapse dimensions for time series data Module introduction A common use case is transforming compound indicators to two or more discrete dimensions to make the dataset easier to query or as a precursor to processing operations. The inverse where multiple dimensions are collapsed into a compound indicator is also used for simplifying datasets with complex internal structures ready for public dissemination.\nIn this module you will learn how to achieve both of these transformations using SDMX Structure Maps and FMR\u0026rsquo;s data transformation services.\nLearning objectives SDMX 3.0 structure mapping principles Prepare a SDMX Structure Map to transform a dataset splitting a compound indicator into a number of discrete dimensions Execute the transformation using FMR\u0026rsquo;s web user interface Prepare a SDMX Structure map to simplify the structure of a dataset by collapsing several dimensions into a single compound indicator Prerequisites Prerequisites\nA good understanding of data domain modelling using SDMX is required including use of the following artefacts: Concepts, Codelists, Data Structure Definitions and Dataflows A basic understanding of the principles of SDMX structure mapping Units in this module "},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/data-conversion-fundamentals/005-edifact-format/","title":"Unit 05 EDI data transmission formats","tags":["EDI"],"description":"Unit 05 EDI data transmission formats","content":"Introduction CSV was introduced as a transmission format for data only as an addition to SDMX 2.1 and was subsequently updated with the release of SDMX 3.0.\nLike JSON, there are two distinct versions of the data message:\nversion 1 supports the SDMX 2.1 information model version 2 supports the SDMX 3.0 information model In this unit we\u0026rsquo;ll look at the general principles of the SDMX CSV data messages and note the differences between the two versions.\nSDMX-CSV v1 data transmission message The SDMX-CSV v1 data message specification was added to SDMX 2.1 to provide a more convenient way to work with SDMX datasets using standard software tools like Excel, \u0026lsquo;R\u0026rsquo;, Tableau, Power BI and other business intelligence and statistics packages.\nThe CSV follows a standard 2-dimensional table layout with fixed columns and one row per observation.\nThere must be one column for the dataflow, one column per dimension, one column for the primary measure and one column per attribute. All dimensions defined in the Dataflow\u0026rsquo;s Data Structure Definition (DSD) must be included.\nA header row defines the meaning of each column.\nIn the simple case the value of each component is just the Id:\nDATAFLOW, REF_AREA, INDICATOR, SUB_INDICATOR, FREQ, TIME_PERIOD, OBS_VALUE\rWB:GCI(1.0), GHA, GCI, RANK, A, 2008, 102\rWB:GCI(1.0), GHA, GCI, RANK, A, 2009, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2010, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2011, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2012, 103\rWB:GCI(1.0), GHA, GCI, RANK, A, 2013, 114\rWB:GCI(1.0), GHA, GCI, RANK, A, 2014, 111 Component Names (sometimes called Labels) can also be included by encoding each value as Id : Name as follows:\nDATAFLOW, REF_AREA:Reference Area, INDICATOR:Indicator, SUB_INDICATOR:Sub Indicator, FREQ:Frequency, TIME_PERIOD:Time period, OBS_VALUE:Observation\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2008, 102\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2009, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2010, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2011, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2012, 103\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2013, 114\rWB:GCI(1.0): Global Competitiveness Index, GHA: Ghana, GCI: Global Competitiveness Index, RANK: Rank, A: Annual, 2014, 111 SDMX-CSV v2 data transmission message The SDMX-CSV v2 data message follows the same general principle of one observation per row.\nV2 was introduced with SDMX 3.0 and includes support for the additional features added to that version of the standard, in particular:\nmultiple measures complex attributes and measures : multi-lingual values and arrays of values transmission of reference metadata linked to the data as part of the data message Datasets are also no longer restricted to just Dataflows and can instead reference a Dataflow, Data Structure Definition or a Provision Agreement. SDMX-CSV v2 supports this by changing the first two columns to describe the structure type (STRUCTURE : dataflow, datastructure or dataprovision) and its Id (STRUCTURE_ID)\nIn addition, the third column now specifies the action type (ACTION) bringing CSV into line with the XML and JSON formats that already provide for this, and better supporting the data exchange use case. The SDMX technical specifications define four action types which are encoded in a v2 CSV message using single characters:\nI - Information - the data is intended for informational purposes only, but treated as Append by the receiver A - Append - instructs incremental update of existing observations by the received R - Replace - instructs the receiver that existing observations should be replaced or appended if they don\u0026rsquo;t already exist D - Delete - instructs the receiver to delete the referenced data There can be a mix of action types within a single data message.\nThe following simple example message has three observations for the dataflow ESTAT:CENS_91SMSTA(1.0) with an action type of I indicating that the data is for information purposes only. Note that OBS_STATUS is an optional observation level attribute.\nSTRUCTURE,STRUCTURE_ID,ACTION,FREQ,MARSTA,AGE,SEX,UNIT,GEO,TIME_PERIOD,OBS_VALUE,TIME_FORMAT,OBS_STATUS dataflow,ESTAT:CENS_91SMSTA(1.0),I,A,TOTAL,Y25-29,F,PER,FR,1991,2162398,P1Y, dataflow,ESTAT:CENS_91SMSTA(1.0),I,A,TOTAL,Y25-29,M,PER,FR,1991,2147582,P1Y, dataflow,ESTAT:CENS_91SMSTA(1.0),I,A,TOTAL,Y25-29,T,PER,FR,1991,4309980,P1Y, Tips and points to note Values that contain commas must be enclosed in double-quotes\nSome implementations support delimiters other than comma, semi-colon (;) for instance.\nRecap The SDMX standard has two versions of the CSV data transmission message, both of which are in use All SDMX-CSV messages have one observation per row v1 was introduced as an addition to SDMX 2.1 v2 was introduced with SDMX 3.0, follows the same principles and structure as the v1 message but with extensions to support the additional SDMX 3.0 information model features including multiple measures, complex attributes and reference metadata in transit with the data The v2 message also adds support for action type providing better support for the data exchange use case - v1 by contrast was best suited to data query response Replication of component Ids and possibly names (labels) for each observation make CSV inefficient for large datasets In the next unit In the next unit we\u0026rsquo;ll look at the legacy GESMES / EDIFACT EDI data message which remains in use\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/getting-start-running-in-docker/005-install-and-operate-docker-desktop/","title":"Unit 05 Install and operate Docker Desktop","tags":["Docker"],"description":"","content":" Skip this unit if you already understand how to use Docker Desktop.\nIn this unit In this unit we\u0026rsquo;ll learn how to install Docker Desktop and basic operations.\nGet Docker Desktop The machine will need at least 4GB of memory.\nOn Windows Double-click Docker Desktop Installer.exe to run the installer. Download the installer from Docker Hub. It typically downloads to your Downloads folder, or you can run it from the recent downloads bar at the bottom of your web browser.\nWhen prompted, ensure the Use WSL 2 instead of Hyper-V option on the Configuration page is selected or not depending on your choice of backend. If your system only supports one of the two options, you will not be able to select which backend to use.\nFollow the instructions on the installation wizard to authorize the installer and proceed with the install.\nWhen the installation is successful, click Close to complete the installation process.\nIf your admin account is different to your user account, you must add the user to the docker-users group. Run Computer Management as an administrator and navigate to Local Users and Groups \u0026gt; Groups \u0026gt; docker-users. Right-click to add the user to the group. Log out and log back in for the changes to take effect.\nThe Docker documentation has additional details: https://docs.docker.com/desktop/install/windows-install/\nOn Mac For Macs with Intel chips, note that macOS must be version 10.15 or newer.\nDouble-click Docker.dmg to open the installer, then drag the Docker icon to the Applications folder. Download the installer from Docker Hub.\nDouble-click Docker.app in the Applications folder to start Docker Desktop.\nUsing the Docker command line interface The task of pulling images from the Docker Hub repository and creating containers is best done using the Docker Command Line Interface.\nStart by opening a command prompt window\u0026hellip;\nIn Windows you can use either:\nCommand Prompt Powershell On Macs, use the Terminal app.\nEverything is done using the docker command. In the following Windows example, the docker images command returns a list of images that have been pulled into the local Docker Desktop.\nThe following Docker commands are the most useful when working with the containerised FMR:\nDocker command Action docker pull [image name] Pull the named image from Docker Hub downloading it to the local machine docker container create [container details] Create a container from a pulled image docker start [container name] Start the named container docker stop [container name] Stop the named container docker images List the pulled Docker images docker ps List the active containers docker ps -a List all containers including those that are inactive Working with the Docker Desktop user interface The Docker Desktop graphical user interface provides an alternative way to view and manage containers and images.\nYou\u0026rsquo;ll find it easier to use the graphical interface for the following tasks:\nDeleting unneeded or out of date images and containers Starting, stopping and pausing a running container Opening a terminal session on a running container allowing control of its processes, access to the embedded MySQL operating database and access to the filesystem including FMR\u0026rsquo;s runtime and error logs Recap Install Docker Desktop by downloading for Mac or Windows from Docker Hub The Docker command line interface can be used for pulling images, creating containers and other administrative tasks The Docker Desktop graphical user interface provides a good way to view images and containers, and is convenient for tasks including starting container terminal sessions, starting, stopping and pausing running containers, and deleting unused containers and images In the next unit In the next unit we\u0026rsquo;ll learn how to use Docker command line to create a running FMR container.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/getting-start-running-in-docker/006-run-fmr-docker-container/","title":"Unit 06 Create and run an FMR Docker container","tags":["Docker"],"description":"","content":"In this unit In this final unit we\u0026rsquo;ll learn how to use Docker command line to pull the image for the latest FMR version, start a running container and begin working with FMR.\nStart an FMR container from Docker command line Using Docker command line, execute the following commands:\nPull the latest FMR image from Docker Hub:\ndocker pull metadatatechnology/fmr-mysql:latest This could take a few minutes while layers that make up the image are downloaded from Docker Hub.\nCreate a container called \u0026lsquo;fmr\u0026rsquo;:\ndocker container create --name fmr --publish 8080:8080 metadatatechnology/fmr-mysql:latest The --publish 8080:8080 tells Docker to export the container\u0026rsquo;s internal port 8080 to the host machine using the same port number. When we later come to work with the running FMR, we\u0026rsquo;ll see that the URL references port 8080.\nStart the container:\ndocker start fmr The container will take between one and two minutes to start.\nUsing a web browser, navigate to: http://localhost:8080/\nThe FMR web user interface will appear when start-up is complete\nThe container can be stopped using the following command:\ndocker stop fmr Log in to add and maintain metadata, and administer the registry In the standard Docker image, FMR is configured with a single superuser account called \u0026lsquo;root\u0026rsquo;.\nLogging-in as this account allows the user to:\nAdd and maintain structural metadata Administer the system and configure the settings The default credentials are:\nUsername: root\nPassword: password\nIt\u0026rsquo;s good practice to change the default root password to something more secure inless the container is being used for personal or non-critical testing. Do this from the Security menu choosing \u0026lsquo;Root User Account\u0026rsquo;.\nTips and points to note Any metadata added to the registry will be persisted in the container.\nThus FMR containers can be stopped and restarted as required without loosing any work.\nDeleting a container will also delete any structural metadata held in its registry.\nFMR can additionally use an external Microsoft Active Directory or Open LDAP directory service for user authentication allowing other user accounts in addition to the default \u0026lsquo;root\u0026rsquo; account.\nThe procedure for is outside of the scope of this module.\nRecap The three Docker command line commands needed to start an FMR container from scratch are: docker pull, docker container create and docker start Use the internal \u0026lsquo;root\u0026rsquo; superuser account to add and maintain structural metadata, administer the system an configure the settings - but change the password from the default for security reasons A container can be stopped and restarted without losing its metadata content, but the content will be destroyed if the container is deleted "},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tags/csv/","title":"CSV","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tags/edi/","title":"EDI","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/fmr/","title":"Fusion Metadata Registry","tags":[],"description":"Fusion Metadata Registry - SDMX 3.0 structural metadata registry","content":"e-learning modules SIO-2201 Running FMR in Docker Learn how to run the FMR software in a Docker container\nIn this module we introduce a simple and quick way to get started with Fusion Metadata Registry by running the software in a \u0026lsquo;Docker container\u0026rsquo;.\nFusion Metadata Registry (FMR) is principally a structural metadata registry. We\u0026rsquo;ll explore what that means and how it can be used including a high-level introduction to the SDMX 3.0 information model, an understanding of which is essential to work effectively with FMR.\nThe principles of \u0026lsquo;software containerisation\u0026rsquo; are covered for those new to the subject, and the module concludes with a step-by-step guide on how to deploy FMR on a desktop PC or Mac in practice using the Docker Desktop container environment.\nIntroductory Business User FMR\nSIO-2202 Data conversion fundamentals Learn how to convert SDMX data between transmission formats using FMR\nThis module introduces the various SDMX transmission formats for exchanging statistical data and explores how datasets can be converted from one format to another interactively using FMR\u0026rsquo;s web user interface, and programatically with the REST API.\nIntroductory Business User FMR\nSIO-2203 Transform multi-measure non-time series data to time series Learn how to transform multi-measure sets of timestamped observations into time series using SDMX structure mapping and FMR\u0026#39;s data processing function\nThis module introduces the various SDMX transmission formats for exchanging statistical data and explores how datasets can be converted from one format to another interactively using FMR\u0026rsquo;s web user interface, and programatically with the REST API.\nAdvanced Business User FMR\nSIO-2204 Split out or collapse dimensions for time series data Learn how to SDMX structure mapping and FMR\u0026#39;s data mapping function to split out or collapse dimensions for time series data\nA common use case is transforming compound indicators to two or more discrete dimensions to make the dataset easier to query or as a precursor to processing operations. The inverse where multiple dimensions are collapsed into a compound indicator is also used for simplifying datasets with complex internal structures ready for public dissemination. In this module you will learn how to achieve both of these transformations using SDMX Structure Maps and FMR\u0026rsquo;s data transformation services.\nIntermediate Business User FMR\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/","title":"sdmx.io e-learning library","tags":[],"description":"","content":"sdmx.io e-learning library SIO-2201 Running FMR in Docker Learn how to run the FMR software in a Docker container\nIn this module we introduce a simple and quick way to get started with Fusion Metadata Registry by running the software in a \u0026lsquo;Docker container\u0026rsquo;.\nFusion Metadata Registry (FMR) is principally a structural metadata registry. We\u0026rsquo;ll explore what that means and how it can be used including a high-level introduction to the SDMX 3.0 information model, an understanding of which is essential to work effectively with FMR.\nThe principles of \u0026lsquo;software containerisation\u0026rsquo; are covered for those new to the subject, and the module concludes with a step-by-step guide on how to deploy FMR on a desktop PC or Mac in practice using the Docker Desktop container environment.\nIntroductory Business User FMR\nSIO-2202 Data conversion fundamentals Learn how to convert SDMX data between transmission formats using FMR\nThis module introduces the various SDMX transmission formats for exchanging statistical data and explores how datasets can be converted from one format to another interactively using FMR\u0026rsquo;s web user interface, and programatically with the REST API.\nIntroductory Business User FMR\nSIO-2203 Transform multi-measure non-time series data to time series Learn how to transform multi-measure sets of timestamped observations into time series using SDMX structure mapping and FMR\u0026#39;s data processing function\nThis module introduces the various SDMX transmission formats for exchanging statistical data and explores how datasets can be converted from one format to another interactively using FMR\u0026rsquo;s web user interface, and programatically with the REST API.\nAdvanced Business User FMR\nSIO-2204 Split out or collapse dimensions for time series data Learn how to SDMX structure mapping and FMR\u0026#39;s data mapping function to split out or collapse dimensions for time series data\nA common use case is transforming compound indicators to two or more discrete dimensions to make the dataset easier to query or as a precursor to processing operations. The inverse where multiple dimensions are collapsed into a compound indicator is also used for simplifying datasets with complex internal structures ready for public dissemination. In this module you will learn how to achieve both of these transformations using SDMX Structure Maps and FMR\u0026rsquo;s data transformation services.\nIntermediate Business User FMR\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tools/","title":"sdmx.io tools","tags":[],"description":"sdmx.io open source software tools for official statistics","content":"Categories Fusion Metadata Registry "},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tags/","title":"Tags","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tags/json/","title":"JSON","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tags/sdmx/","title":"SDMX","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tags/xml/","title":"XML","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/tags/docker/","title":"Docker","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/_footer/","title":"sdmx.io e-learning","tags":[],"description":"","content":"Copyright 2022 Bank for International Settlements. All rights reserved.\n"},{"uri":"https://metadatatechnology.github.io/sdmxiolearn/_header/","title":"sdmx.io e-learning","tags":[],"description":"e-learning resources","content":" e-learning\n"}]